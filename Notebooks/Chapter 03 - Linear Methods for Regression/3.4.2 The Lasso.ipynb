{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Lasso\n",
    "\n",
    "The lasso is a shrinkage method like ridge with one major difference: the penalty term. In ridge regression the penalty term is defined as $\\lambda\\sum_{j=1}^p \\beta_j^2$, while in lasso it's defined as $\\lambda\\sum_{j=1}^p |\\beta_j|$. This later penalty makes the solution nonlinear and there is no closed-form solution as in ridge regression.\n",
    "\n",
    "The lasso solution is a quadratic programming problem. However, as we can see in section 3.4.4, we can use *LARS* with a slight modification to obtain lasso solution.\n",
    "\n",
    "In this notebook, we try to implement the lasso-modified LARS from scratch, and to do that we need to understand how the original *LARS* algorithm works:\n",
    "\n",
    "   * Initialization\n",
    "       * First, we need to standarize all the predictors $\\mathbf{X}$ to have a zero mean and unit variance, and set all the initial coefficients to zero $\\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0$. The initial residual is $r = y - \\bar y$\n",
    "       * Find the feature $j$ that has the highest absolute correlation with the residue $r$\n",
    "       $$j = \\underset{j}{\\text{argmax }} |\\mathbf{X}^T r|$$\n",
    "       * Add $j$ to the active set $A$\n",
    "\n",
    "   * For every step $k$\n",
    "       * Move $\\beta[A]$ in the direction of:\n",
    "       $$\\delta_k = \\left(\\mathbf{X}[A_k]^\\top\\mathbf{X}[A_k]\\right)^{-1}\\mathbf{X}[A_k]^\\top r$$\n",
    "       \n",
    "       The coefficient profile evolves as:\n",
    "       $$\\beta[A_k](\\alpha) = \\beta[A_k] + \\alpha \\delta_k$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "import scipy.stats\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from ml_datasets.esl import ProstateCancer\n",
    "from esl.utils import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_cancer = ProstateCancer(verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prostate_cancer.load()\n",
    "# extract input and output dataframe\n",
    "train_test = prostate_cancer.train_test\n",
    "df_x = df[prostate_cancer.meta[:-1]]\n",
    "df_y = df[prostate_cancer.meta[-1]]\n",
    "\n",
    "x_train = scale(df_x[train_test=='T'].copy()).values\n",
    "y_train =  df_y[train_test=='T'].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(x, y, nfold=10):\n",
    "    num_data = len(y)\n",
    "    index = np.arange(num_data)\n",
    "    np.random.seed(2)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    num_data = len(y)\n",
    "    avg = len(index) / float(nfold)\n",
    "    last = 0.0\n",
    "    \n",
    "    x_dict = dict()\n",
    "    y_dict = dict()\n",
    "    \n",
    "    i = 0\n",
    "    while last < num_data:\n",
    "        index_val = index[int(last):int(last + avg)]\n",
    "#         print(last, avg, int(last + avg))\n",
    "        index_train = np.array([j for j in range(num_data) if j not in index_val])\n",
    "        \n",
    "        y_dict[9 - i] = {'train': y[index_train], 'val': y[index_val]}\n",
    "        x_dict[9 - i] = {'train': x[index_train, :], 'val': x[index_val, :]}\n",
    "        \n",
    "        last += avg\n",
    "        i += 1\n",
    "    \n",
    "    return x_dict, y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_dict, y_dict = kfold(x_train, y_train, nfold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2.45234509 0.87888041 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "n, p = x_train.shape\n",
    "\n",
    "# get initial residual by subtracting the mean of y_train from y_train\n",
    "res =  y_train - np.mean(y_train)\n",
    "x_intercept = np.ones_like(x_train[:, 0]).reshape(-1, 1)\n",
    "\n",
    "intercept = np.linalg.inv(x_intercept.T @ x_intercept) @ x_intercept.T @ y_train\n",
    "\n",
    "# initial correlation\n",
    "x_train_ = np.hstack([x_intercept, x_train])\n",
    "corr = x_train_[:, 1:].T @ residual\n",
    "best_index = np.argmax(np.abs(corr)) + 1\n",
    "\n",
    "# initialize active set A\n",
    "A = [0, best_index]\n",
    "# A.add(best_index)\n",
    "print(A)\n",
    "beta = np.zeros(p + 1)\n",
    "beta[0] = intercept\n",
    "\n",
    "beta[A] = np.linalg.inv(x_train_[:, A].T @ x_train_[:, A]) @ x_train_[:, A].T @ y_train\n",
    "print(beta)\n",
    "# # initialize sign array sj\n",
    "# sign = np.zeros(p)\n",
    "# # sign[list(A)] = np.sign(corr[list(A)])\n",
    "\n",
    "# mu_hat_A = x_train[:, list(A)] @ beta[list(A)]\n",
    "\n",
    "# for k in range(1, p + 1):\n",
    "#     # residue at step k on the active set A\n",
    "#     res = y_train - mu_hat_A\n",
    "    \n",
    "#     corr = x_train.T @ res\n",
    "#     corr_best_index = np.argmax(np.abs(corr))\n",
    "    \n",
    "#     corr_best = corr[corr_best_index]\n",
    "#     sign[list(A)] = np.sign(corr[list(A)])\n",
    "    \n",
    "#     X_A = np.multiply(sign, x_train)[:, list(A)]\n",
    "#     I_A = np.ones(len(A))\n",
    "#     G_A = np.array(X_A.T @  X_A)\n",
    "#     A_A = np.sqrt(1 / (I_A.T @ np.linalg.inv(G_A) @ I_A))\n",
    "\n",
    "#     w_A = A_A * np.linalg.inv(G_A) @ I_A\n",
    "    \n",
    "#     # equiangular vector\n",
    "#     u_A = X_A @ w_A \n",
    "    \n",
    "#     # angle\n",
    "#     a = x_train.T @ u_A\n",
    "#     print(a)\n",
    "#     # this loop  finds gamma\n",
    "\n",
    "#     # if not in the last step\n",
    "#     if k < p:\n",
    "#         gamma = np.inf\n",
    "#         for j in np.arange(p):\n",
    "\n",
    "#             # this is because we want j in A-complement, or j not in A\n",
    "#             if j in list(A):\n",
    "#                 continue\n",
    "\n",
    "#             left = (corr_best - corr[j]) / (A_A - a[j])\n",
    "#             if left < 0:\n",
    "#                 left = np.inf\n",
    "\n",
    "#             right = (corr_best + corr[j]) / (A_A + a[j])\n",
    "#             if right < 0:\n",
    "#                 right = np.inf\n",
    "\n",
    "#             gamma_temp = np.min([left, right])\n",
    "#             if gamma_temp < gamma:\n",
    "#                 gamma = gamma_temp\n",
    "#                 best_j = j\n",
    "                \n",
    "#     else:\n",
    "#         gamma = corr_best / A_A\n",
    "\n",
    "#     beta[list(A)] = beta[list(A)] + gamma * np.linalg.inv(X_A.T @ X_A) @ X_A.T @ res\n",
    "# #     mu_hat_A = mu_hat_A + gamma * u_A\n",
    "\n",
    "# print(beta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in np.arange(p):\n",
    "    residual = y_train - y_hat\n",
    "    \n",
    "    mse = np.mean(residual.T @ residual)\n",
    "    \n",
    "    pred = x_train @ beta\n",
    "    \n",
    "    corr = x_train.T @ residual\n",
    "    \n",
    "    Xa = X[:, list(active_set)]\n",
    "    Xa *= sing[list(active_set)]\n",
    "    \n",
    "    Ga = Xa.T @ Xa\n",
    "    Ga = Xa.T @ Xa\n",
    "    Ga_inv = np.linalg(Ga)\n",
    "    Ga_inv_red_cols = np.sum(Ga_inv, 1)\n",
    "    \n",
    "    Aa = 1 / np.sqrst(np.sum(Ga_inv_red_cols))\n",
    "    omega = Aa * Ga_inv_red_cols\n",
    "    \n",
    "    equiangular = Xa @ omega\n",
    "    \n",
    "    cos_angle = x_train.T @ equiangular\n",
    "    gamma = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    corr_best_idx = np.argmax(corr)\n",
    "    A[:, corr_best_idx] = x_train[:, corr_best_idx]\n",
    "    \n",
    "    delta[corr_best_idx] = A[:, corr_best_idx].T @ r\n",
    "    \n",
    "    beta_hat[corr_best_idx]  = beta_hat[corr_best_idx]  + alpha * delta[corr_best_idx] \n",
    "\n",
    "    f = A[:, corr_best_idx] * beta_hat[corr_best_idx]\n",
    "    \n",
    "    r = r - f\n",
    "    \n",
    "    u = A[:, corr_best_idx] * delta[corr_best_idx]\n",
    "    f = f + alpha * u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.11881477e+02 -1.16249216e+17  0.00000000e+00  3.74581278e+05\n",
      "  2.26675088e+05  0.00000000e+00  5.87804135e+16  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:esl]",
   "language": "python",
   "name": "conda-env-esl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
